# Chap.1 Introduction
Definition: An operating system is the layer of software that manages a computer’s resources for its users and their applications.

-Users
-User-mode: Apps, System Library?
-Kernel-mode: File System, TCP/IP networking, CPU scheduling, Virtual Memory
Hardware specific software, drivers
-Hardware: CPU, GPU, Network

- Resource Allocation
- Fault islation
- Communication

Virtualization, virtual machine, guest operating system
Reliability, Availability (MTTF, MTTR)
Security, Privacy: Enforcement
Portable
AMI: API
Hardware Abstraction Layer (HAL)
Efficiency, Overload, Fairness
Response time, Throughput
Proprietary v.s. open system
Batch OS, DMA, multi-tasking
Time-sharing

Desktop, laptop, netbook: Win 7, MacOS, Linux
Smartphone OS: iOS, Android, Windows Phone, 
Embedded systems
Virtual machines: VMWare
Server OS, 

# Chap.2 Kernels and Processes
Source code -> executable image -> Process(machine instructions, data, heap, stack)
PCB (process control block)
Dual-mode: user-mode, kernel-mode (1-bit processor status register)
- previleged instructions
- Memory protection: base and bounds (unable to do 4 things: expandable heap and stack, memory sharing, non-relativememory address, memory fragmentation (MS-DOS: no memory protection)
- Virtual address:
- Timer interrupts: os regain control from app, hardware timer (expires every 10 ms)
# Preemptive scheduling
# Three reasons why the kernel takes control from a user process: 
1. exceptions: divided by zero, write on read-only memory...
2. interrupts: external events occurred, I/O (mouse, Ethernet, WiFi, harddisk, keyboard)
polling: kernel could loop to check each I/O device 
3. system calls: user transition to OS, request kernel do some ops on the user's behalf (use trap instruction)
# Kernel to user mode
new process, resume from exceptions/interrupts/system calls, switch to a different process, user-level upcall
Interrupt vector (a special register points to an area of kernel memory)
Interrupt stack
- If the process is running on the processor in user-mode, its kernel stack is empty, ready to be used for an interrupt.
- If the process is running on the processor in kernel-mode, e.g., due to an interrupt, exception or system call trap, its kernel stack is in use, containing the saved registers from the suspended user-level computation, as well as the current state of the kernel handler.
- If the process is available to run but is waiting for its turn on the processor, its kernel stack contains the registers and state to be restored when the process is resumed.
- If the process is waiting for an I/O event to complete, its kernel stack contains the suspended computation to be resumed when the I/O finishes.
Interrupt masking
- Multiple interrupts arrive asynchronously, defer and mask
# Context Switch
1. Save three key values (stack pointer, execution flags, instruction pointer)
2. Switch onto the kernel exception stack;
3. Push three key values onto the new stack
4. Optionally save error code;
5. Invoke the interrupt handler;
# System Call
Pair of stubs: 
Kernel stub: 1. locate system call arguments; 2. validate parameters; 3. copy before check; 4. copy back any results;
# Upcalls: virtualized interrupts and exceptions
Linux: signals; Windows: asynchronous events;
Preemptive user-level thread package; Asynchronous I/O notification; Interprocess communication; User-level exception handling; User-level resource allocation policy;
# Architectural support for fast mode switches: SPARC
# Registers:
CS: code segment;
DS: data segment;
SS: stack segment;
ES: extra segment;
EAX: accumulator
EBX: base address
ECX: counter
EDX: to save reminder after division
ESI/EDI: source/destination index
EBP: base pointer, pointing to the bottom
ESP: stack (or heap?) pointer, pointing to the top
EIP:
EFLAGS:
# Case Study: booting an OS
1. Boot ROM: in x86, BIOS (Basic I/O System)
2. bootloader (a bit for check), cryptographic signature, should be protected from virus
3. load the OS from the file system;
4. Kernel starts first process: login
# Case Study: Virtual Machines
host OS v.s. guest OS

# Chap 3. The Programming Interface
Process Management, I/O, Thread Management, Memory management, 
File system and storage, networking and distributed system
Graphics and window management, Authentication and security
- Flexibility
- Safety
- Reliability: Improved reliability is another reason to keep the operating system kernel minimal
- Performance: transferring control into the kernel is more ex- pensive than a procedure call to a library,
# 3.1 Process Management
Shell: a job control system
parent/child process
- Windows process management: CreateProcess, 
- Unix process management: fork(), exec(program_name, Arguments[])
 fork() creates a complete copy of parent, then call exec()
# 5 steps of fork():
1. Create and initialize the process control block (PCB) in the kernel;
2. Create a new address space;
3. Initialize the address space with a copy of the entire contents of the address space of the parent;
4. Inherit the execution context of the parent (e.g., any open files)
5. Inform the scheduler that the new process is ready to run;
A strange aspect of UNIX fork is that the system call returns twice: once to the parent and once to the child. To the parent, UNIX returns the process ID of the child; to the child, it returns 0 indicating success
# 3 steps of exec()
1. Load the program prog into the current address space
2. Copy arguments args into memory in the address space
3. Initialize the hardware context to start execution at “start”
Note that exec does not create a new process!
As we discussed in the previous chapter, when a UNIX process finishes, it calls the system call exit(). PCB reclaimed when both parent and child have finished.
# wait() system call
pauses the parent until the child finishes, crashes, or is terminated
“UNIX wait” to refer to UNIX’s wait() system call
# 3.2 Input/Output
Basic Ideas:
1. Uniformity. All device I/O, file operations, and interprocess communi- cation use the same set of system calls: open, close, read and write.
2. Open before use: open() returns a handle;
3. Kernel-buffered reads: Stream data, such as from the network or key- board, is stored in a kernel buffer and returned to the application on request.
4. Kernel-buffered writes:
5. Explicit close: close()
For interprocess communication, we need two more system calls:
1. Pipes: (TCP is similar)
2. Replace file descriptor
3. Wait for multiple reads
### A list of system calls
# Create a child process as a clone of the current process; // fork returns to both the parent and child
fork ()

# Run the application ‘‘prog’’ in the current process
exec(prog , args)

# Tell the kernel the current process is complete,
# and its data structures should be garbage collected 
exit ()

# Pause until the child process has exited
wait(process_ID)

# Send an interrupt of ‘‘type’’ to a process
signal(process_ID , type)

# Open a file or hardware device , specified by ‘‘name ’’;
# returns a file descriptor that can be used by other calls
fd = open(name)

# Create a one-directional pipe between two processes;
# returns two file descriptors , one for reading , one for writing 
pipe(fd[2])

# Replace the to_fd file descriptor with a copy of from_fd; // used for replacing stdin/stdout
dup2(from_fd , to_fd)

# Read up to ‘‘size’’ bytes into buffer, from the device, file or channel.
# ‘‘read’’ returns the number of bytes actually read; for streaming
# devices this will often be less than ‘‘size’’.
# For example, a read from the keyboard device will return all of its queued bytes. 
int read(fd, buffer, size)

# Analogous to ‘‘read’’, write up to ‘‘size’’ bytes into kernel output // buffer for a device, file or channel.
# ‘‘write’’ normally returns immediately, but may stall if there is
# no space in the kernel buffer.
int write(fd, buffer, size)

# Return when any of the file descriptors in the array have data available to be read. // Returns the file descriptor with the data.
fd = select(fd[], number)

# Tell the kernel the process is done with this device, file, or channel.
close(fd)

# 3.3 Case Study: Implementing a Shell
stdin, stdout
- A program can be a file of commands.
- A program can send its output to a file.
- A program can read its output from a file.
- The output of one program can be the input to another program
# Producer/ Consumer

# 3.4 Case Study: Interprocess communication
Three widely used forms:
- Producer-consumer: Producer only writes, consumer only reads (Google's Mapreduce)
- Client-server: two-way, client sends requests, server replies back when complete
- File system: can be separated in time

# 3.5.1 Monolithic Kernels
Def: most of the operating system functionality runs inside the operating system kernel.
Hardware Abstraction Layer (HAL)
dynamically loadable device driver
# 3.5.2 Microkernel
Def: to run as much of the operating system as possible in one or more user-level servers.
Window manager
+ easier to modularize and debug user-level services
- little benefit to end users; slow down overall performance by inserting extra steps between the application and the services it needs.
In practice: hybrid model

# 3.6 Conclusion and Future Directions
Unix Interface (powerful and compact)
A key aspect of the UNIX interface are that creating a process (with fork) is separate from starting to run a program in that process (with exec);
another key feature is the use of kernel buffers to decouple reading and writing data through the kernel.

# Chap.4 Concurrency and Threads
Threads: A core abstraction for concurrency.
# 4.1 Threads: Abstraction and interface
Multi-threaded programs
- Program structure: Expressing logically concurrent tasks.
- Performance: Exploiting multiple processors.
- Performance: Coping with high-latency I/O devices. 
# Definition
A single execution sequence that represents a separately schedu- lable task.
Running, suspending, and resuming threads.
each thread runs on a dedicated virtual processor with unpredictable and variable speed
Cooperative multithreading v.s. Preemptive
# 4.2 Simple API and example
void sthread create(thread, func, arg)
void sthread yield()
int sthread join(thread)
void sthread exit(ret)
# 4.3 Thread internals
Thread control block (TCB) and per-thread state
- The state of the computation being performed by the thread
stack, Copy of processor registers
- Metadata about the thread that is used to manage the thread
Life Cycle:
Init -> Ready -> Running -> Waiting
# 4.4 Implementation details
# Create:
Allocating per-thread state ->
Initializing per-thread state.
# Delete:
remove it from the ready list so that it will never run again;
free the per-thread state we allocated for it.
# Thread context switch
PCB v.s. TCB: similar, all store registers when not running, address
process switch v.s. thread switch: Hardware-triggered (interrupts and exceptions.); Software-triggered (library calls v. system calls);
# Reasons for multi-threads
1. Program structure.
2. Exploiting multiple processors.
3. Coping with high latency I/O devices.
Similar mechanism like timer interrupt to suspend long-running thread
# Hybrid implementations. 
Although today few threads packages operate completely at user level, many split their work between the user-level library and the operating system kernel to reduce overheads by avoiding mode switches into the kernel for some of their operations.
# 4.5 Asynchronous I/O and event-driven programming
The basic idea is to allow a process to make a system call to issue and I/O request but not wait for the result.
read() v.s. aio_read()
Definition: event-driven programming pattern
# Comparison
1. Performance: Coping with high-latency I/O devices. Either approach— event-driven or threads—can be used to overlap I/O and processing.
Today, less clear-cut.
2. Performance: Exploiting multiple processors. The event-driven approach does not help a program exploit multiple processors.
3. Program structure: Expressing logically concurrent tasks.
# 4.6 Conclusion and future directions
Besides threads and event-driven programming, other approaches also parallel:
- Data parallel programs. Data parallel programming or SIMD (single instruction multiple data)
e.g., matrix manuplication, SQL, multimedia streams, GPU
- Distributed and parallel processing.

# Chap.5 Synchronizing Access to Shared Objects
Definition: independent threads
Definition: Cooperating threads: per-thread state (stack and registers), shared state (shared data on heap)
# 3 reasons of break down:
1. Program execution depends on the interleavings of threads’ access to shared state.
2. Program execution can be nondeterministic.
3. Compilers and architectures reorder instructions.
# Structured synchronization.
# 5.1 Challenges
- Race condition: when the behavior of a program depends on the interleaving of operations of di↵erent threads
- Atomic operations (ops can't be interleaved or split): a load or store of a 32-bit
- Too much milk problem
Safety, liveness
stable property
- Lock: ensures both, same codes on each 
# 5.2 Shared objects and synchronization
Synchronization variable
State variables
Atomic read-modify-write instructions
# 5.3 Lock: Mutual Exclusion
Lock::acquire(), Lock::release()
Formal properties
1. Mutual Exclusion: At most one thread holds the lock.
2. Progress.
3. Bounded waiting: If thread T attempts to acquire a lock, then there exists a bound on the number times other threads successfully acquire the lock before T does.

Critical sections: A sequence of code that operates on shared state
# 5.4 Condition Variables: Waiting for a Change
CV::wait(Lock *lock)
CV::signal()
CV::broadcast()
Condition variables integrate with locks.
1. A condition variable is memoryless; the condition variable, itself, has no internal state other than a queue of waiting threads.
2. Wait() atomically releases the lock.
3. When a waiting thread is reenabled via signal() or broadcast(), it may not run immediately.
# 5.4.3 Example: Blocking bounded queue


